<!DOCTYPE html><!--MxYiNWk4quuhVs61JRztT--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/70bc3e132a0a741e-s.p.15008bfb.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/chunks/1c829eb1a0acf55c.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/f277faa9b1e0c21b.js"/><script src="/_next/static/chunks/650936c2802db2e9.js" async=""></script><script src="/_next/static/chunks/56c4540d48641cb3.js" async=""></script><script src="/_next/static/chunks/turbopack-c4e7a033bd5f3178.js" async=""></script><script src="/_next/static/chunks/26e32ce0f3dab796.js" async=""></script><script src="/_next/static/chunks/8de45eb4f6a714c4.js" async=""></script><script src="/_next/static/chunks/aa1e5871f0d87419.js" async=""></script><script src="/_next/static/chunks/dad6c2f98a0d17a5.js" async=""></script><link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" as="style"/><link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" as="style"/><meta name="next-size-adjust" content=""/><title>Fanyou Wu | 吴凡优</title><meta name="description" content="Personal website of Fanyou Wu"/><link rel="icon" href="/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><link rel="icon" href="/assets/img/favicon.ico"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="inter_5901b7c6-module__ec5Qua__variable jetbrains_mono_d5591ac2-module__D88TVW__variable pt-20"><div hidden=""><!--$--><!--/$--></div><nav class="fixed top-0 left-0 right-0 z-50 bg-white shadow-sm"><div class="gradient-bar"></div><div class="container-main flex items-center justify-between h-14"><a class="navbar-brand text-black no-underline hover:no-underline text-lg" href="/"><span class="font-semibold">Fanyou</span> Wu | 吴凡优</a><button class="sm:hidden flex flex-col gap-1 p-2" aria-label="Toggle navigation"><span class="block w-5.5 h-0.5 bg-gray-600 rounded transition-all "></span><span class="block w-5.5 h-0.5 bg-gray-600 rounded transition-all "></span><span class="block w-5.5 h-0.5 bg-gray-600 rounded transition-all "></span></button><ul class="hidden sm:flex gap-6 items-center"><li><a class="nav-link no-underline text-black hover:no-underline nav-link-active" href="/">About</a></li><li><a class="nav-link no-underline text-black hover:no-underline " href="/competition">Competition</a></li><li><a class="nav-link no-underline text-black hover:no-underline " href="/presentation">Presentation</a></li><li><a class="nav-link no-underline text-black hover:no-underline " href="/publication">Publication</a></li></ul></div></nav><div class="container-main mt-5"><div><header class="mb-6"><h1 class="text-3xl font-light">Fanyou Wu | 吴凡优</h1></header><article><div class="sm:float-right sm:w-[22%] sm:ml-6 mb-4"><img alt="Fanyou Wu" loading="lazy" width="300" height="300" decoding="async" data-nimg="1" class="rounded shadow-sm w-full" style="color:transparent" src="/assets/img/wu1297.jpg"/><div class="social-icons mt-2 flex flex-wrap justify-center gap-2"><a href="mailto:fanyou.wu@outlook.com" title="Email"><i class="fas fa-envelope"></i></a><a href="https://orcid.org/0000-0002-4894-5738" target="_blank" rel="noopener noreferrer" title="ORCID"><i class="ai ai-orcid"></i></a><a href="https://scholar.google.com/citations?user=C8WYCTAAAAAJ" target="_blank" rel="noopener noreferrer" title="Google Scholar"><i class="ai ai-google-scholar"></i></a><a href="https://github.com/wufanyou" target="_blank" rel="noopener noreferrer" title="GitHub"><i class="fab fa-github"></i></a><a href="/assets/pdf/Fanyou_Wu_Resume.pdf" target="_blank" title="Resume"><i class="ai ai-cv"></i></a></div></div><div class="clearfix leading-relaxed space-y-4"><p>Applied Scientist II<br/>PXT Central Science (PXTCS)<br/>Amazon</p><p>I am Fanyou Wu, and I am an Applied Scientist at Amazon PXT Central Science (PXTCS). I received my Ph.D. degree in Forestry from<!-- --> <a href="https://fnr.purdue.edu/">Department of Forestry and Natural Resources, Purdue University</a> <!-- -->(2021). Before attending Purdue, I received my master&#x27;s degree from<!-- --> <a href="https://www.uef.fi/en/etusivu">University of Eastern Finland</a> <!-- -->(2018) and bachelor&#x27;s degree from<!-- --> <a href="http://eng.njfu.edu.cn">Nanjing Forestry University</a> (2015) both in Wood Material Science. I was also an exchange student at the<!-- --> <a href="https://www.ubc.ca/">University of British Columbia</a> (2013).</p><p>My research focuses on applying machine learning to human resource area. Attending machine learning related <a href="/competition">competitions</a> <!-- -->is my side interests, and I have won many championships and runners-up in machine learning related competitions and top conference competitions at KDD, IJCAI, NeurIPS, and CVPR.</p></div><div class="mt-8"><h2 class="section-heading">News</h2><table class="news-table w-full"><tbody><tr><th class="py-2">Feb 24, 2026</th><td class="py-2">I used Claude Code remote control to update my personal webpage.</td></tr><tr><th class="py-2">Feb 21, 2026</th><td class="py-2">I have migrated my website from jekyll to next.js using Claude Code.</td></tr></tbody></table></div><div class="publications mt-8"><h2 class="section-heading">Selected publications</h2><ol class="list-none p-0"><li class="mb-0.5 "><div class="pub-card"><div class="flex gap-2"><div class="w-10 text-center flex-shrink-0 flex items-start justify-center pt-1"><span class="inline-flex items-center justify-center text-[#0076df]"><svg viewBox="0 0 24 24" width="24" height="24" fill="currentColor"><path d="M3 17.25V21h3.75L17.81 9.94l-3.75-3.75L3 17.25zM20.71 7.04a1 1 0 0 0 0-1.41l-2.34-2.34a1 1 0 0 0-1.41 0l-1.83 1.83 3.75 3.75 1.83-1.83z"></path></svg></span></div><div class="flex-1 min-w-0"><div class="pub-title">Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning</div><div class="pub-author text-sm"><span>Zheyuan Liu<!-- -->, </span><span>Suraj Maharjan<!-- -->, </span><span><em>Fanyou Wu</em>, </span><span>Rahil Parikh<!-- -->, </span><span>Belhassen Bayar<!-- -->, </span><span>Srinivasan H. Sengamedu<!-- -->, </span><span>Meng Jiang</span></div><div class="text-sm text-gray-600 italic">Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics<!-- --> <span class="font-mono">2025</span></div><div class="pub-links mt-1"><a href="#" role="button">bibtex</a><a href="#" role="button">abstract</a><a href="https://aclanthology.org/2025.acl-long.305/" target="_blank" rel="noopener noreferrer">HTML</a></div><div class="hidden-section "><pre>@inproceedings{liu2025disentangling,
  title = {Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning},
  author = {Liu, Zheyuan and Maharjan, Suraj and Wu, Fanyou and Parikh, Rahil and Bayar, Belhassen and Sengamedu, Srinivasan H. and Jiang, Meng},
  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics},
  year = {2025},
  doi = {10.18653/v1/2025.acl-long.305}
}</pre></div><div class="hidden-section "><p>The rapid development of Large Language Models (LLMs) has led to their widespread adoption across various domains, leveraging vast pre-training knowledge and impressive generalization capabilities. However, these models often inherit biased knowledge, resulting in unfair decisions in sensitive applications. It is challenging to remove this biased knowledge without compromising reasoning abilities due to the entangled nature of the learned knowledge within LLMs. To solve this problem, existing approaches have attempted to mitigate the bias using techniques such as fine-tuning with unbiased datasets, model merging, and gradient ascent. While these methods have experimentally proven effective, they can still be sub-optimum in fully disentangling biases from reasoning. To address this gap, we propose Selective Disentanglement Unlearning (SDU), a novel unlearning framework that selectively removes biased knowledge while preserving reasoning capabilities. SDU operates in three stages: identifying biased parameters using a shadow LLM, fine-tuning with unbiased data, and performing selective parameter updates based on weight saliency. Experimental results across multiple LLMs show that SDU improves fairness accuracy by 14.7% and enhances reasoning performance by 62.6% compared to existing baselines.</p></div></div><div class="w-12 flex-shrink-0"></div></div></div></li><li class="mb-0.5 "><div class="pub-card"><div class="flex gap-2"><div class="w-10 text-center flex-shrink-0 flex items-start justify-center pt-1"><span class="inline-flex items-center justify-center text-[#0076df]"><svg viewBox="0 0 24 24" width="24" height="24" fill="currentColor"><path d="M3 17.25V21h3.75L17.81 9.94l-3.75-3.75L3 17.25zM20.71 7.04a1 1 0 0 0 0-1.41l-2.34-2.34a1 1 0 0 0-1.41 0l-1.83 1.83 3.75 3.75 1.83-1.83z"></path></svg></span></div><div class="flex-1 min-w-0"><div class="pub-title">Synthesizing conversations from unlabeled documents using automatic response segmentation</div><div class="pub-author text-sm"><span><em>Fanyou Wu</em>, </span><span>Weijie Xu<!-- -->, </span><span>K. Chandan Reddy<!-- -->, </span><span>H. Srinivasan Sengamedu</span></div><div class="text-sm text-gray-600 italic">Findings of the Association for Computational Linguistics: ACL<!-- --> <span class="font-mono">2024</span></div><div class="pub-links mt-1"><a href="#" role="button">bibtex</a><a href="https://aclanthology.org/2024.findings-acl.477/" target="_blank" rel="noopener noreferrer">HTML</a></div><div class="hidden-section "><pre>@inproceedings{wu2024SynCARS,
  title = {Synthesizing conversations from unlabeled documents using automatic response segmentation},
  author = {Wu, Fanyou and Xu, Weijie and Reddy, K. Chandan and Sengamedu, H. Srinivasan},
  booktitle = {Findings of the Association for Computational Linguistics: ACL},
  year = {2024}
}</pre></div></div><div class="w-12 flex-shrink-0"></div></div></div></li><li class="mb-0.5 "><div class="pub-card"><div class="flex gap-2"><div class="w-10 text-center flex-shrink-0 flex items-start justify-center pt-1"><span class="inline-flex items-center justify-center text-[#0076df]"><svg viewBox="0 0 24 24" width="24" height="24" fill="currentColor"><path d="M18.92 6.01C18.72 5.42 18.16 5 17.5 5h-11c-.66 0-1.21.42-1.42 1.01L3 12v8c0 .55.45 1 1 1h1c.55 0 1-.45 1-1v-1h12v1c0 .55.45 1 1 1h1c.55 0 1-.45 1-1v-8l-2.08-5.99zM6.5 16c-.83 0-1.5-.67-1.5-1.5S5.67 13 6.5 13s1.5.67 1.5 1.5S7.33 16 6.5 16zm11 0c-.83 0-1.5-.67-1.5-1.5s.67-1.5 1.5-1.5 1.5.67 1.5 1.5-.67 1.5-1.5 1.5zM5 11l1.5-4.5h11L19 11H5z"></path></svg></span></div><div class="flex-1 min-w-0"><div class="pub-title">Can language models be used for real-world urban-delivery route optimization?</div><div class="pub-author text-sm"><span>Yang Liu<!-- -->, </span><span><em>Fanyou Wu</em>, </span><span>Zhiyuan Liu<!-- -->, </span><span>Kai Wang<!-- -->, </span><span>Feiyue Wang<!-- -->, </span><span>Xiaobo Qu</span></div><div class="text-sm text-gray-600 italic">The Innovation<!-- --> <span class="font-mono">2023</span></div><div class="pub-links mt-1"><a href="#" role="button">bibtex</a><a href="https://doi.org/10.1016/j.xinn.2023.100520" target="_blank" rel="noopener noreferrer">HTML</a></div><div class="hidden-section "><pre>@article{liu2023can,
  title = {Can language models be used for real-world urban-delivery route optimization?},
  author = {Liu, Yang and Wu, Fanyou and Liu, Zhiyuan and Wang, Kai and Wang, Feiyue and Qu, Xiaobo},
  journal = {The Innovation},
  year = {2023},
  doi = {10.1016/j.xinn.2023.100520},
  publisher = {Elsevier}
}</pre></div></div><div class="w-12 flex-shrink-0"></div></div></div></li><li class="mb-0.5 "><div class="pub-card"><div class="flex gap-2"><div class="w-10 text-center flex-shrink-0 flex items-start justify-center pt-1"><span class="inline-flex items-center justify-center text-[#0076df]"><svg viewBox="0 0 24 24" width="24" height="24" fill="currentColor"><path d="M12 2L4 14h5v8h6v-8h5z"></path></svg></span></div><div class="flex-1 min-w-0"><div class="pub-title">Data Collection and Deep Learning-Based Detection of Wood Growth Rings</div><div class="pub-author text-sm"><span><em>Fanyou Wu</em>, </span><span>Yunmei Huang<!-- -->, </span><span>Bedrich Benes<!-- -->, </span><span>Charles Warner<!-- -->, </span><span>Rado Gazo</span></div><div class="text-sm text-gray-600 italic">Information Processing in Agriculture<!-- --> <span class="font-mono">2023</span></div><div class="pub-links mt-1"><a href="#" role="button">bibtex</a><a href="#" role="button">abstract</a><a href="https://www.sciencedirect.com/science/article/pii/S2214317323000781" target="_blank" rel="noopener noreferrer">HTML</a></div><div class="hidden-section "><pre>@article{wu2023ring,
  title = {Data Collection and Deep Learning-Based Detection of Wood Growth Rings},
  author = {Wu, Fanyou and Huang, Yunmei and Benes, Bedrich and Warner, Charles and Gazo, Rado},
  journal = {Information Processing in Agriculture},
  year = {2023}
}</pre></div><div class="hidden-section "><p>Tree-ring dating enables gathering necessary knowledge about trees, and it is essential in many areas, including forest management and the timber industry. Treering dating can be conducted on either wood&#x27;s clean cross-sections or tree trunks&#x27; rough end cross-sections. However, the measurement process is still time-consuming and frequently requires experts who use special devices, such as stereoscopes. Modern approaches based on image processing using deep learning have been successfully applied in many areas, and they can succeed in recognizing tree rings. While supervised deep learning-based methods often produce excellent results, they also depend on extensive datasets of tediously annotated data. To our knowledge, there are only a few publicly available ring image datasets with annotations. We introduce a new carefully captured dataset of images of hardwood species automatically annotated for tree ring detection. We capture each wood cookie twice, once in the rough form, similar to industrial settings, and then after careful cleaning, that reveals all growth rings. We carefully overlap the images and use them for an automatic ring annotation in the rough data. We then use the Feature Pyramid Network with Resnet encoder that obtains an overall pixel-level area under the curve score of 85.72% and ring level F1 score of 0.7348.</p></div></div><div class="w-12 flex-shrink-0"></div></div></div></li><li class="mb-0.5 "><div class="pub-card"><div class="flex gap-2"><div class="w-10 text-center flex-shrink-0 flex items-start justify-center pt-1"><span class="inline-flex items-center justify-center text-[#0076df]"><svg viewBox="0 0 24 24" width="24" height="24" fill="currentColor"><path d="M18.92 6.01C18.72 5.42 18.16 5 17.5 5h-11c-.66 0-1.21.42-1.42 1.01L3 12v8c0 .55.45 1 1 1h1c.55 0 1-.45 1-1v-1h12v1c0 .55.45 1 1 1h1c.55 0 1-.45 1-1v-8l-2.08-5.99zM6.5 16c-.83 0-1.5-.67-1.5-1.5S5.67 13 6.5 13s1.5.67 1.5 1.5S7.33 16 6.5 16zm11 0c-.83 0-1.5-.67-1.5-1.5s.67-1.5 1.5-1.5 1.5.67 1.5 1.5-.67 1.5-1.5 1.5zM5 11l1.5-4.5h11L19 11H5z"></path></svg></span></div><div class="flex-1 min-w-0"><div class="pub-title">Deep dispatching: A deep reinforcement learning approach for vehicle dispatching on online ride-hailing platform</div><div class="pub-author text-sm"><span>Yang Liu<!-- -->, </span><span><em>Fanyou Wu</em>, </span><span>Cheng Lyu<!-- -->, </span><span>Shen Li<!-- -->, </span><span>Jiepin Ye<!-- -->, </span><span>Xiaobo Qu</span></div><div class="text-sm text-gray-600 italic">Transportation Research Part E<!-- --> <span class="font-mono">2022</span></div><div class="pub-links mt-1"><a href="#" role="button">bibtex</a><a href="#" role="button">abstract</a><a href="https://doi.org/10.1016/j.tre.2022.102694" target="_blank" rel="noopener noreferrer">HTML</a></div><div class="hidden-section "><pre>@article{liu2022learning,
  title = {Deep dispatching: A deep reinforcement learning approach for vehicle dispatching on online ride-hailing platform},
  author = {Liu, Yang and Wu, Fanyou and Lyu, Cheng and Li, Shen and Ye, Jiepin and Qu, Xiaobo},
  journal = {Transportation Research Part E},
  year = {2022},
  doi = {10.1016/j.tre.2022.102694}
}</pre></div><div class="hidden-section "><p>The vehicle dispatching system is one of the most critical problems in online taxi-hailing platforms, which requires adapting the operation and management strategy to the dynamics of demand and supply. In this paper, we propose a single-agent deep reinforcement learning approach for the vehicle repositioning problem by reallocating vacant vehicles to regions with a large demand gap in advance. The simulator and the vehicle repositioning algorithm are designed based on industrial-scale real-world data and the workflow of online taxi-hailing platforms, ensuring the practical value of our approach. Besides, the vehicle repositioning problem is translated in analogy with the load balancing problem in computers. Inspired by the recommendation system, the high concurrency of repositioning requests is addressed by sorting the actions as a recommendation list, whereby matching action with requests. Experiments demonstrate that the proposed approach is superior to the existing ones. It is also worth noting that the proposed approach won first place in the vehicle repositioning task of KDD Cup 2020.</p></div></div><div class="w-12 flex-shrink-0"></div></div></div></li><li class="mb-0.5 "><div class="pub-card"><div class="flex gap-2"><div class="w-10 text-center flex-shrink-0 flex items-start justify-center pt-1"><span class="inline-flex items-center justify-center text-[#0076df]"><svg viewBox="0 0 24 24" width="24" height="24" fill="currentColor"><path d="M12 2L4 14h5v8h6v-8h5z"></path></svg></span></div><div class="flex-1 min-w-0"><div class="pub-title">Deep BarkID: A Portable Tree Bark Identification System by Knowledge Distillation</div><div class="pub-author text-sm"><span><em>Fanyou Wu</em>, </span><span>Rado Gazo<!-- -->, </span><span>Bedrich Benes<!-- -->, </span><span>Eva Haviarova</span></div><div class="text-sm text-gray-600 italic">European Journal of Forest Research<!-- --> <span class="font-mono">2021</span></div><div class="pub-links mt-1"><a href="#" role="button">bibtex</a><a href="#" role="button">abstract</a><a href="https://link.springer.com/article/10.1007/s10342-021-01407-7" target="_blank" rel="noopener noreferrer">HTML</a><a href="https://github.com/wufanyou/DBID" target="_blank" rel="noopener noreferrer">Code</a></div><div class="hidden-section "><pre>@article{wu2021bark,
  title = {Deep BarkID: A Portable Tree Bark Identification System by Knowledge Distillation},
  author = {Wu, Fanyou and Gazo, Rado and Benes, Bedrich and Haviarova, Eva},
  journal = {European Journal of Forest Research},
  year = {2021},
  doi = {10.1007/s10342-021-01407-7}
}</pre></div><div class="hidden-section "><p>Species identification is one of the key steps in the management and conservation planning of many forest ecosystems. We introduce Deep BarkID, a portable tree identification system that detects tree species from bark images. Existing bark identification systems rely heavily on massive computing power access, which may be scarce in many locations. Our approach is deployed as a smartphone application that does not require any connection to a database. Its intended use is in a forest, where internet connection is often unavailable. The tree bark identification is expressed as a bark image classification task, and it is implemented as a convolutional neural network (CNN). This research focuses on developing light-weight CNN models through knowledge distillation. Overall, we achieved 96.12% accuracy for tree species classification tasks for ten common tree species in Indiana, USA. We also captured and prepared thousands of bark images—a dataset that we call Indiana Bark Dataset—and we make it available at https://github.com/wufanyou/DBID.</p></div></div><div class="w-12 flex-shrink-0"></div></div></div></li><li class="mb-0.5 "><div class="pub-card"><div class="flex gap-2"><div class="w-10 text-center flex-shrink-0 flex items-start justify-center pt-1"><span class="inline-flex items-center justify-center text-[#0076df]"><svg viewBox="0 0 24 24" width="24" height="24" fill="currentColor"><path d="M12 2L4 14h5v8h6v-8h5z"></path></svg></span></div><div class="flex-1 min-w-0"><div class="pub-title">Wood Identification Based on Longitudinal Section Images by Using Deep Learning</div><div class="pub-author text-sm"><span><em>Fanyou Wu</em>, </span><span>Rado Gazo<!-- -->, </span><span>Eva Haviarova<!-- -->, </span><span>Bedrich Benes</span></div><div class="text-sm text-gray-600 italic">Wood Science and Technology<!-- --> <span class="font-mono">2021</span></div><div class="pub-links mt-1"><a href="#" role="button">bibtex</a><a href="#" role="button">abstract</a><a href="https://link.springer.com/article/10.1007/s00226-021-01261-1" target="_blank" rel="noopener noreferrer">HTML</a><a href="https://github.com/wufanyou/lumber_identification" target="_blank" rel="noopener noreferrer">Code</a></div><div class="hidden-section "><pre>@article{wu2021wood,
  title = {Wood Identification Based on Longitudinal Section Images by Using Deep Learning},
  author = {Wu, Fanyou and Gazo, Rado and Haviarova, Eva and Benes, Bedrich},
  journal = {Wood Science and Technology},
  year = {2021},
  doi = {10.1007/s00226-021-01261-1},
  volume = {55},
  number = {2},
  pages = {553-563}
}</pre></div><div class="hidden-section "><p>Automatic species identification has the potential to improve the efficacy and automation of wood processing systems significantly. Recent advances in deep learning allowed for the automation of many previously difficult tasks, and in this paper, we investigate the feasibility of using Deep Convolutional Neural Networks (CNNs) for hardwood lumber identification. In particular, we tested two highly effective CNNs (ResNet-50 and DenseNet-121) as well as lightweight MobileNet-V2. Overall, we achieved 98.2% accuracy for 11 common hardwood species classification tasks.</p></div></div><div class="w-12 flex-shrink-0"></div></div></div></li></ol></div></article></div><!--$--><!--/$--></div><footer class="mt-10"><div class="container-main"><div class="footer-separator"></div><div>© <!-- -->2026<!-- --> Fanyou Wu</div><div class="text-gray-500 text-xs mt-1">Generated by<!-- --> <a href="https://code.claude.com/docs/en/overview" target="_blank" rel="noopener noreferrer">Claude Code</a>. Updated on <span class="font-mono">2026-02-24</span>.</div></div></footer><script src="/_next/static/chunks/f277faa9b1e0c21b.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[51299,[\"/_next/static/chunks/26e32ce0f3dab796.js\"],\"default\"]\n3:I[72958,[\"/_next/static/chunks/8de45eb4f6a714c4.js\",\"/_next/static/chunks/aa1e5871f0d87419.js\"],\"default\"]\n4:I[40250,[\"/_next/static/chunks/8de45eb4f6a714c4.js\",\"/_next/static/chunks/aa1e5871f0d87419.js\"],\"default\"]\n5:I[18927,[\"/_next/static/chunks/26e32ce0f3dab796.js\",\"/_next/static/chunks/dad6c2f98a0d17a5.js\"],\"Image\"]\n10:I[51301,[],\"default\"]\n:HL[\"/_next/static/chunks/1c829eb1a0acf55c.css\",\"style\"]\n:HL[\"/_next/static/media/70bc3e132a0a741e-s.p.15008bfb.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css\",\"style\"]\n:HL[\"https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"MxYiNWk4quuhVs61JRztT\",\"c\":[\"\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/1c829eb1a0acf55c.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/26e32ce0f3dab796.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css\"}],[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css\"}]]}],[\"$\",\"body\",null,{\"className\":\"inter_5901b7c6-module__ec5Qua__variable jetbrains_mono_d5591ac2-module__D88TVW__variable pt-20\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"div\",null,{\"className\":\"container-main mt-5\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"mt-10\",\"children\":[\"$\",\"div\",null,{\"className\":\"container-main\",\"children\":[[\"$\",\"div\",null,{\"className\":\"footer-separator\"}],[\"$\",\"div\",null,{\"children\":[\"© \",2026,\" Fanyou Wu\"]}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-xs mt-1\",\"children\":[\"Generated by\",\" \",[\"$\",\"a\",null,{\"href\":\"https://code.claude.com/docs/en/overview\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"Claude Code\"}],\". Updated on \",[\"$\",\"span\",null,{\"className\":\"font-mono\",\"children\":\"2026-02-24\"}],\".\"]}]]}]}]]}]]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-6\",\"children\":[\"$\",\"h1\",null,{\"className\":\"text-3xl font-light\",\"children\":\"Fanyou Wu | 吴凡优\"}]}],[\"$\",\"article\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"sm:float-right sm:w-[22%] sm:ml-6 mb-4\",\"children\":[[\"$\",\"$L5\",null,{\"src\":\"/assets/img/wu1297.jpg\",\"alt\":\"Fanyou Wu\",\"width\":300,\"height\":300,\"className\":\"rounded shadow-sm w-full\"}],[\"$\",\"div\",null,{\"className\":\"social-icons mt-2 flex flex-wrap justify-center gap-2\",\"children\":[[\"$\",\"a\",null,{\"href\":\"mailto:fanyou.wu@outlook.com\",\"title\":\"Email\",\"children\":[\"$\",\"i\",null,{\"className\":\"fas fa-envelope\"}]}],[\"$\",\"a\",null,{\"href\":\"https://orcid.org/0000-0002-4894-5738\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"title\":\"ORCID\",\"children\":[\"$\",\"i\",null,{\"className\":\"ai ai-orcid\"}]}],[\"$\",\"a\",null,{\"href\":\"https://scholar.google.com/citations?user=C8WYCTAAAAAJ\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"title\":\"Google Scholar\",\"children\":[\"$\",\"i\",null,{\"className\":\"ai ai-google-scholar\"}]}],[\"$\",\"a\",null,{\"href\":\"https://github.com/wufanyou\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"title\":\"GitHub\",\"children\":[\"$\",\"i\",null,{\"className\":\"fab fa-github\"}]}],[\"$\",\"a\",null,{\"href\":\"/assets/pdf/Fanyou_Wu_Resume.pdf\",\"target\":\"_blank\",\"title\":\"Resume\",\"children\":[\"$\",\"i\",null,{\"className\":\"ai ai-cv\"}]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"clearfix leading-relaxed space-y-4\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"Applied Scientist II\",[\"$\",\"br\",null,{}],\"PXT Central Science (PXTCS)\",[\"$\",\"br\",null,{}],\"Amazon\"]}],[\"$\",\"p\",null,{\"children\":[\"I am Fanyou Wu, and I am an Applied Scientist at Amazon PXT Central Science (PXTCS). I received my Ph.D. degree in Forestry from\",\" \",\"$L6\",\" \",\"(2021). Before attending Purdue, I received my master's degree from\",\" \",\"$L7\",\" \",\"(2018) and bachelor's degree from\",\" \",\"$L8\",\" (2015) both in Wood Material Science. I was also an exchange student at the\",\" \",\"$L9\",\" (2013).\"]}],\"$La\"]}],\"$Lb\",\"$Lc\"]}]]}],[\"$Ld\"],\"$Le\"]}],{},null,false,false]},null,false,false],\"$Lf\",false]],\"m\":\"$undefined\",\"G\":[\"$10\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"11:I[72736,[\"/_next/static/chunks/26e32ce0f3dab796.js\",\"/_next/static/chunks/dad6c2f98a0d17a5.js\"],\"default\"]\n18:I[99013,[\"/_next/static/chunks/8de45eb4f6a714c4.js\",\"/_next/static/chunks/aa1e5871f0d87419.js\"],\"OutletBoundary\"]\n19:\"$Sreact.suspense\"\n1b:I[99013,[\"/_next/static/chunks/8de45eb4f6a714c4.js\",\"/_next/static/chunks/aa1e5871f0d87419.js\"],\"ViewportBoundary\"]\n1d:I[99013,[\"/_next/static/chunks/8de45eb4f6a714c4.js\",\"/_next/static/chunks/aa1e5871f0d87419.js\"],\"MetadataBoundary\"]\n6:[\"$\",\"a\",null,{\"href\":\"https://fnr.purdue.edu/\",\"children\":\"Department of Forestry and Natural Resources, Purdue University\"}]\n7:[\"$\",\"a\",null,{\"href\":\"https://www.uef.fi/en/etusivu\",\"children\":\"University of Eastern Finland\"}]\n8:[\"$\",\"a\",null,{\"href\":\"http://eng.njfu.edu.cn\",\"children\":\"Nanjing Forestry University\"}]\n9:[\"$\",\"a\",null,{\"href\":\"https://www.ubc.ca/\",\"children\":\"University of British Columbia\"}]\na:[\"$\",\"p\",null,{\"children\":[\"My research focuses on applying machine learning to human resource area. Attending machine learning related \",[\"$\",\"a\",null,{\"href\":\"/competition\",\"children\":\"competitions\"}],\" \",\"is my side interests, and I have won many championships and runners-up in machine learning related competitions and top conference competitions at KDD, IJCAI, NeurIPS, and CVPR.\"]}]\nb:[\"$\",\"div\",null,{\"className\":\"mt-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"section-heading\",\"children\":\"News\"}],[\"$\",\"table\",null,{\"className\":\"news-table w-full\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",\"0\",{\"children\":[[\"$\",\"th\",null,{\"className\":\"py-2\",\"children\":\"Feb 24, 2026\"}],[\"$\",\"td\",null,{\"className\":\"py-2\",\"dangerouslySetInnerHTML\":{\"__html\":\"I used Claude Code remote control to update my personal webpage.\"}}]]}],[\"$\",\"tr\",\"1\",{\"children\":[[\"$\",\"th\",null,{\"className\":\"py-2\",\"children\":\"Feb 21, 2026\"}],[\"$\",\"td\",null,{\"className\":\"py-2\",\"dangerouslySetInnerHTML\":{\"__html\":\"I have migrated my website from jekyll to next.js using Claude Code.\"}}]]}]]}]}]]}]\n12:T520,The rapid development of Large Language Models (LLMs) has led to their widespread adoption across various domains, leveraging vast pre-training knowledge and impressive generalization capabilities. However, these models often inherit biased knowledge, resulting in unfair decisions in sensitive applications. It is challenging to remove this biased knowledge without compromising reasoning abilities due to the entangled nature of the learned knowledge within LLMs. To solve this problem, existing approaches have attempted to mitigate the bias using techniques such as fine-tuning with unbiased datasets, model merging, and gradient ascent. While these methods have experimentally proven effective, they can still be sub-optimum in fully disentangling biases from reasoning. To address this gap, we propose Selective Disentanglement Unlearning (SDU), a novel unlearning framework that selectively removes biased knowledge while preserving reasoning capabilities. SDU operates in three stages: identifying biased parameters using a shadow LLM, fine-tuning with unbiased data, and performing selective parameter updates based on weight saliency. Experimental results across multiple LLMs show that SDU improves fairness accuracy by 14.7% and enhances reasoning performance by 62.6% compared to existing baselines."])</script><script>self.__next_f.push([1,"c:[\"$\",\"div\",null,{\"className\":\"publications mt-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"section-heading\",\"children\":\"Selected publications\"}],[\"$\",\"ol\",null,{\"className\":\"list-none p-0\",\"children\":[[\"$\",\"$L11\",\"liu2025disentangling\",{\"pub\":{\"key\":\"liu2025disentangling\",\"type\":\"inproceedings\",\"title\":\"Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning\",\"author\":\"Liu, Zheyuan and Maharjan, Suraj and Wu, Fanyou and Parikh, Rahil and Bayar, Belhassen and Sengamedu, Srinivasan H. and Jiang, Meng\",\"authors\":[\"Zheyuan Liu\",\"Suraj Maharjan\",\"Fanyou Wu\",\"Rahil Parikh\",\"Belhassen Bayar\",\"Srinivasan H. Sengamedu\",\"Meng Jiang\"],\"year\":\"2025\",\"journal\":\"$undefined\",\"booktitle\":\"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics\",\"venue\":\"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics\",\"doi\":\"10.18653/v1/2025.acl-long.305\",\"arxiv\":\"$undefined\",\"html\":\"https://aclanthology.org/2025.acl-long.305/\",\"pdf\":\"$undefined\",\"code\":\"$undefined\",\"emoji\":\"pen\",\"selected\":true,\"abstract\":\"$12\",\"volume\":\"$undefined\",\"number\":\"$undefined\",\"pages\":\"$undefined\",\"rawBibtex\":\"@inproceedings{liu2025disentangling,\\n  title = {Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning},\\n  author = {Liu, Zheyuan and Maharjan, Suraj and Wu, Fanyou and Parikh, Rahil and Bayar, Belhassen and Sengamedu, Srinivasan H. and Jiang, Meng},\\n  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics},\\n  year = {2025},\\n  doi = {10.18653/v1/2025.acl-long.305}\\n}\"}}],[\"$\",\"$L11\",\"wu2024SynCARS\",{\"pub\":{\"key\":\"wu2024SynCARS\",\"type\":\"inproceedings\",\"title\":\"Synthesizing conversations from unlabeled documents using automatic response segmentation\",\"author\":\"Wu, Fanyou and Xu, Weijie and Reddy, K. Chandan and Sengamedu, H. Srinivasan\",\"authors\":[\"Fanyou Wu\",\"Weijie Xu\",\"K. Chandan Reddy\",\"H. Srinivasan Sengamedu\"],\"year\":\"2024\",\"journal\":\"$undefined\",\"booktitle\":\"Findings of the Association for Computational Linguistics: ACL\",\"venue\":\"Findings of the Association for Computational Linguistics: ACL\",\"doi\":\"$undefined\",\"arxiv\":\"$undefined\",\"html\":\"https://aclanthology.org/2024.findings-acl.477/\",\"pdf\":\"$undefined\",\"code\":\"$undefined\",\"emoji\":\"pen\",\"selected\":true,\"abstract\":\"$undefined\",\"volume\":\"$undefined\",\"number\":\"$undefined\",\"pages\":\"$undefined\",\"rawBibtex\":\"@inproceedings{wu2024SynCARS,\\n  title = {Synthesizing conversations from unlabeled documents using automatic response segmentation},\\n  author = {Wu, Fanyou and Xu, Weijie and Reddy, K. Chandan and Sengamedu, H. Srinivasan},\\n  booktitle = {Findings of the Association for Computational Linguistics: ACL},\\n  year = {2024}\\n}\"}}],\"$L13\",\"$L14\",\"$L15\",\"$L16\",\"$L17\"]}]]}]\n"])</script><script>self.__next_f.push([1,"d:[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/dad6c2f98a0d17a5.js\",\"async\":true,\"nonce\":\"$undefined\"}]\ne:[\"$\",\"$L18\",null,{\"children\":[\"$\",\"$19\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@1a\"}]}]\nf:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L1b\",null,{\"children\":\"$L1c\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L1d\",null,{\"children\":[\"$\",\"$19\",null,{\"name\":\"Next.Metadata\",\"children\":\"$L1e\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]\n"])</script><script>self.__next_f.push([1,"13:[\"$\",\"$L11\",\"liu2023can\",{\"pub\":{\"key\":\"liu2023can\",\"type\":\"article\",\"title\":\"Can language models be used for real-world urban-delivery route optimization?\",\"author\":\"Liu, Yang and Wu, Fanyou and Liu, Zhiyuan and Wang, Kai and Wang, Feiyue and Qu, Xiaobo\",\"authors\":[\"Yang Liu\",\"Fanyou Wu\",\"Zhiyuan Liu\",\"Kai Wang\",\"Feiyue Wang\",\"Xiaobo Qu\"],\"year\":\"2023\",\"journal\":\"The Innovation\",\"booktitle\":\"$undefined\",\"venue\":\"The Innovation\",\"doi\":\"10.1016/j.xinn.2023.100520\",\"arxiv\":\"$undefined\",\"html\":\"https://doi.org/10.1016/j.xinn.2023.100520\",\"pdf\":\"$undefined\",\"code\":\"$undefined\",\"emoji\":\"traffic\",\"selected\":true,\"abstract\":\"$undefined\",\"volume\":\"$undefined\",\"number\":\"$undefined\",\"pages\":\"$undefined\",\"rawBibtex\":\"@article{liu2023can,\\n  title = {Can language models be used for real-world urban-delivery route optimization?},\\n  author = {Liu, Yang and Wu, Fanyou and Liu, Zhiyuan and Wang, Kai and Wang, Feiyue and Qu, Xiaobo},\\n  journal = {The Innovation},\\n  year = {2023},\\n  doi = {10.1016/j.xinn.2023.100520},\\n  publisher = {Elsevier}\\n}\"}}]\n1f:T545,Tree-ring dating enables gathering necessary knowledge about trees, and it is essential in many areas, including forest management and the timber industry. Treering dating can be conducted on either wood's clean cross-sections or tree trunks' rough end cross-sections. However, the measurement process is still time-consuming and frequently requires experts who use special devices, such as stereoscopes. Modern approaches based on image processing using deep learning have been successfully applied in many areas, and they can succeed in recognizing tree rings. While supervised deep learning-based methods often produce excellent results, they also depend on extensive datasets of tediously annotated data. To our knowledge, there are only a few publicly available ring image datasets with annotations. We introduce a new carefully captured dataset of images of hardwood species automatically annotated for tree ring detection. We capture each wood cookie twice, once in the rough form, similar to industrial settings, and then after careful cleaning, that reveals all growth rings. We carefully overlap the images and use them for an automatic ring annotation in the rough data. We then use the Feature Pyramid Network with Resnet encoder that obtains an overall pixel-level area under the curve score of 85.72% and ring level F1 score of 0.7348.14:[\"$\",\"$L11\",\"wu2023ring\",{\"pub\":{\"key\":\"wu2023ring\",\"type\":\"article\",\"title\":\"Data Collection and Deep Learning-Based Detection of Wood Growth Rings\",\"author\":\"Wu, Fanyou and Huang, Yunmei and Benes, Bedrich and Warner, Charles and Gazo, Rado\",\"authors\":[\"Fanyou Wu\",\"Yunmei Huang\",\"Bedrich Benes\",\"Charles Warner\",\"Rado Gazo\"],\"year\":\"2023\",\"journal\":\"Information Processing in Agriculture\",\"booktitle\":\"$undefined\",\"venue\":\"Information Processing in Agriculture\",\"doi\":\"$undefined\",\"arxiv\":\"$undefined\",\"html\":\"https://www.sciencedirect.com/science/article/pii/S2214317323000781\",\"pdf\":\"$undefined\",\"code\":\"$undefined\",\"emoji\":\"tree\",\"selected\":true,\"abstract\":\"$1f\",\"volume\":\"$undefined\",\"number\":\"$undefined\",\"pages\":\"$undefined\",\"rawBibtex\":\"@article{wu2023ring,\\n  title = {Data Collection and Deep Learning-Based Detection of Wood Growth Rings},\\n  author = {Wu, Fanyou and Huang, Yunmei and Benes, Bedrich and Warner, Charles and Gazo, Rado},\\n  journal = {Information Processing in Agriculture},\\n  year = {2023}\\n}\"}}]\n20:T452,The vehicle dispatching system is one of the most critical problems in online taxi-hailing platforms, which requires adapting the operation and management strategy to the dynamics of demand and supply. In this paper, we propose a single-agent deep reinforcement learning approach for the vehicle repositioning problem by reallocating vacant vehicles to regions with a large demand gap in advance. The simulator and the vehicle repositioning algorithm are designed based on industrial-scale real-world data and the workflow of online taxi-hailing platforms, ensuring the practical value of our approach. Besides, the vehicle repositioning probl"])</script><script>self.__next_f.push([1,"em is translated in analogy with the load balancing problem in computers. Inspired by the recommendation system, the high concurrency of repositioning requests is addressed by sorting the actions as a recommendation list, whereby matching action with requests. Experiments demonstrate that the proposed approach is superior to the existing ones. It is also worth noting that the proposed approach won first place in the vehicle repositioning task of KDD Cup 2020.15:[\"$\",\"$L11\",\"liu2022learning\",{\"pub\":{\"key\":\"liu2022learning\",\"type\":\"article\",\"title\":\"Deep dispatching: A deep reinforcement learning approach for vehicle dispatching on online ride-hailing platform\",\"author\":\"Liu, Yang and Wu, Fanyou and Lyu, Cheng and Li, Shen and Ye, Jiepin and Qu, Xiaobo\",\"authors\":[\"Yang Liu\",\"Fanyou Wu\",\"Cheng Lyu\",\"Shen Li\",\"Jiepin Ye\",\"Xiaobo Qu\"],\"year\":\"2022\",\"journal\":\"Transportation Research Part E\",\"booktitle\":\"$undefined\",\"venue\":\"Transportation Research Part E\",\"doi\":\"10.1016/j.tre.2022.102694\",\"arxiv\":\"$undefined\",\"html\":\"https://doi.org/10.1016/j.tre.2022.102694\",\"pdf\":\"$undefined\",\"code\":\"$undefined\",\"emoji\":\"traffic\",\"selected\":true,\"abstract\":\"$20\",\"volume\":\"$undefined\",\"number\":\"$undefined\",\"pages\":\"$undefined\",\"rawBibtex\":\"@article{liu2022learning,\\n  title = {Deep dispatching: A deep reinforcement learning approach for vehicle dispatching on online ride-hailing platform},\\n  author = {Liu, Yang and Wu, Fanyou and Lyu, Cheng and Li, Shen and Ye, Jiepin and Qu, Xiaobo},\\n  journal = {Transportation Research Part E},\\n  year = {2022},\\n  doi = {10.1016/j.tre.2022.102694}\\n}\"}}]\n21:T41e,Species identification is one of the key steps in the management and conservation planning of many forest ecosystems. We introduce Deep BarkID, a portable tree identification system that detects tree species from bark images. Existing bark identification systems rely heavily on massive computing power access, which may be scarce in many locations. Our approach is deployed as a smartphone application that does not require any connection to a database. Its intended use is in a forest, where internet connection is often unavailable. The tree bark identification is expressed as a bark image classification task, and it is implemented as a convolutional neural network (CNN). This research focuses on developing light-weight CNN models through knowledge distillation. Overall, we achieved 96.12% accuracy for tree species classification tasks for ten common tree species in Indiana, USA. We also captured and prepared thousands of bark images—a dataset that we call Indiana Bark Dataset—and we make it available at https://github.com/wufanyou/DBID.16:[\"$\",\"$L11\",\"wu2021bark\",{\"pub\":{\"key\":\"wu2021bark\",\"type\":\"article\",\"title\":\"Deep BarkID: A Portable Tree Bark Identification System by Knowledge Distillation\",\"author\":\"Wu, Fanyou and Gazo, Rado and Benes, Bedrich and Haviarova, Eva\",\"authors\":[\"Fanyou Wu\",\"Rado Gazo\",\"Bedrich Benes\",\"Eva Haviarova\"],\"year\":\"2021\",\"journal\":\"European Journal of Forest Research\",\"booktitle\":\"$undefined\",\"venue\":\"European Journal of Forest Research\",\"doi\":\"10.1007/s10342-021-01407-7\",\"arxiv\":\"$undefined\",\"html\":\"https://link.springer.com/article/10.1007/s10342-021-01407-7\",\"pdf\":\"$undefined\",\"code\":\"https://github.com/wufanyou/DBID\",\"emoji\":\"tree\",\"selected\":true,\"abstract\":\"$21\",\"volume\":\"$undefined\",\"number\":\"$undefined\",\"pages\":\"$undefined\",\"rawBibtex\":\"@article{wu2021bark,\\n  title = {Deep BarkID: A Portable Tree Bark Identification System by Knowledge Distillation},\\n  author = {Wu, Fanyou and Gazo, Rado and Benes, Bedrich and Haviarova, Eva},\\n  journal = {European Journal of Forest Research},\\n  year = {2021},\\n  doi = {10.1007/s10342-021-01407-7}\\n}\"}}]\n"])</script><script>self.__next_f.push([1,"17:[\"$\",\"$L11\",\"wu2021wood\",{\"pub\":{\"key\":\"wu2021wood\",\"type\":\"article\",\"title\":\"Wood Identification Based on Longitudinal Section Images by Using Deep Learning\",\"author\":\"Wu, Fanyou and Gazo, Rado and Haviarova, Eva and Benes, Bedrich\",\"authors\":[\"Fanyou Wu\",\"Rado Gazo\",\"Eva Haviarova\",\"Bedrich Benes\"],\"year\":\"2021\",\"journal\":\"Wood Science and Technology\",\"booktitle\":\"$undefined\",\"venue\":\"Wood Science and Technology\",\"doi\":\"10.1007/s00226-021-01261-1\",\"arxiv\":\"$undefined\",\"html\":\"https://link.springer.com/article/10.1007/s00226-021-01261-1\",\"pdf\":\"$undefined\",\"code\":\"https://github.com/wufanyou/lumber_identification\",\"emoji\":\"tree\",\"selected\":true,\"abstract\":\"Automatic species identification has the potential to improve the efficacy and automation of wood processing systems significantly. Recent advances in deep learning allowed for the automation of many previously difficult tasks, and in this paper, we investigate the feasibility of using Deep Convolutional Neural Networks (CNNs) for hardwood lumber identification. In particular, we tested two highly effective CNNs (ResNet-50 and DenseNet-121) as well as lightweight MobileNet-V2. Overall, we achieved 98.2% accuracy for 11 common hardwood species classification tasks.\",\"volume\":\"55\",\"number\":\"2\",\"pages\":\"553-563\",\"rawBibtex\":\"@article{wu2021wood,\\n  title = {Wood Identification Based on Longitudinal Section Images by Using Deep Learning},\\n  author = {Wu, Fanyou and Gazo, Rado and Haviarova, Eva and Benes, Bedrich},\\n  journal = {Wood Science and Technology},\\n  year = {2021},\\n  doi = {10.1007/s00226-021-01261-1},\\n  volume = {55},\\n  number = {2},\\n  pages = {553-563}\\n}\"}}]\n"])</script><script>self.__next_f.push([1,"1c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"22:I[86799,[\"/_next/static/chunks/8de45eb4f6a714c4.js\",\"/_next/static/chunks/aa1e5871f0d87419.js\"],\"IconMark\"]\n1a:null\n1e:[[\"$\",\"title\",\"0\",{\"children\":\"Fanyou Wu | 吴凡优\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Personal website of Fanyou Wu\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/assets/img/favicon.ico\"}],[\"$\",\"$L22\",\"4\",{}]]\n"])</script></body></html>